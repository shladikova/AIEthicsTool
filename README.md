---
layout:
  title:
    visible: true
  description:
    visible: false
  tableOfContents:
    visible: true
  outline:
    visible: true
  pagination:
    visible: true
---

# ðŸ‘‹ Welcome to AI Ethics Tool

{% hint style="info" %}
If you like this tool and find it valuable, please join our [Public Discord!](https://discord.gg/YZM7XcMzAg)
{% endhint %}

## Overview

> [Beneficence](additional-resources/ai-ethics-principles.md#beneficence) relates to the obligations of doing more good than harm. In the context of AI, it means that algorithms, research, and technologies should be developed for the greater benefit of humanity.
> [Non-Maleficence](additional-resources/ai-ethics-principles.md#non-maleficence) relates to the obligation of not doing harm, including obligations to minimize risks or to take precautions against possible risks or harms . Within the context of AI, harm is associated with safety, security, and discrimination.
> [Justice](additional-resources/ai-ethics-principles.md#justice) relates to obligations of distributive justice, procedural justice, and special protection of vulnerable groups . Within the context of AI, it means that the development of AI should promote Justice, seek to eliminate discrimination, promoting diversity, and prevent the rise of new threats to justice.
> [Autonomy](additional-resources/ai-ethics-principles.md#autonomy) relates to protecting and guaranteeing the autonomous choice of individuals and groups. In the context of AI, there is a risk that increasing automation may undermine human autonomy.
> [Explainability](additional-resources/ai-ethics-principles.md#explainability) relates to both intelligibility (How does it work?) and accountability (Who is responsible for the way it works?). AI/ML models have improved prediction beyond what was previously possible. However, due to model complexity, AI/ML models often lose internal model explainability, which may lead to problematic conclusions.


## Quick links

{% content-ref url="overview/development.md" %}
[development.md](overview/development.md)
{% endcontent-ref %}

{% content-ref url="overview/design.md" %}
[design.md](overview/design.md)
{% endcontent-ref %}

{% content-ref url="overview/training.md" %}
[training.md](overview/training.md)
{% endcontent-ref %}

{% content-ref url="overview/building.md" %}
[building.md](overview/building.md)
{% endcontent-ref %}

{% content-ref url="overview/testing.md" %}
[testing.md](overview/testing.md)
{% endcontent-ref %}

{% content-ref url="overview/deployment.md" %}
[deployment.md](overview/deployment.md)
{% endcontent-ref %}

{% content-ref url="overview/monitoring.md" %}
[monitoring.md](overview/monitoring.md)
{% endcontent-ref %}

{% content-ref url="overview/fostering-ethics-and-virtues.md" %}
[fostering-ethics-and-virtues.md](overview/fostering-ethics-and-virtues.md)
{% endcontent-ref %}

{% content-ref url="additional-resources/ai-ethics-principles.md" %}
[ai-ethics-principles.md](additional-resources/ai-ethics-principles.md)
{% endcontent-ref %}

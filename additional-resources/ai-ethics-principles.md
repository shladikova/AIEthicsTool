---
layout:
  title:
    visible: true
  description:
    visible: false
  tableOfContents:
    visible: false
  outline:
    visible: true
  pagination:
    visible: true
---

# ðŸ“– AI Ethics Principles

<mark style="color:blue;">**Beneficence**</mark> relates to the obligations of doing more good than harm. In the context of AI, it means that algorithms, research, and technologies should be developed for the greater benefit of humanity.

***

<mark style="color:blue;">**Non-maleficence**</mark> relates to the obligation of not doing harm, including obligations to minimize risks or to take precautions against possible risks or harms . Within the context of AI, harm is associated with safety, security, and discrimination.

***

<mark style="color:blue;">**Justice**</mark> relates to obligations of distributive justice, procedural justice, and special protection of vulnerable groups . Within the context of AI, it means that the development of AI should promote Justice, seek to eliminate discrimination, promoting diversity, and prevent the rise of new threats to justice.

***

<mark style="color:blue;">**Autonomy**</mark> relates to protecting and guaranteeing the autonomous choice of individuals and groups. In the context of AI, there is a risk that increasing automation may undermine human autonomy.

***

<mark style="color:blue;">**Explainability**</mark> relates to both intelligibility (How does it work?) and accountability (Who is responsible for the way it works?). AI/ML models have improved prediction beyond what was previously possible. However, due to model complexity, AI/ML models often lose internal model explainability, which may lead to problematic conclusions.


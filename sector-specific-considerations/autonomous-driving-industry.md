---
description: >-
  The AI Tool is designed to be technology-agnostic. Following sector-specific
  considerations may serve as a secondary resource for practitioners in the
  Autonomous Vehicles (AVs) industry.
cover: >-
  https://images.unsplash.com/photo-1628573413574-2b35620de9d7?crop=entropy&cs=srgb&fm=jpg&ixid=M3wxOTcwMjR8MHwxfHNlYXJjaHw0fHxhdXRvbm9tb3VzJTIwY2Fyc3xlbnwwfHx8fDE3MDEyMDI0NDR8MA&ixlib=rb-4.0.3&q=85
coverY: 0
layout:
  cover:
    visible: true
    size: full
  title:
    visible: true
  description:
    visible: true
  tableOfContents:
    visible: true
  outline:
    visible: true
  pagination:
    visible: true
---

# ðŸš— Autonomous Driving Industry

## Privacy

Autonomous Vehicles (AVs) rely heavily on data to operate its various functions (planning, learning, etc), which makes these systems vulnerable to privacy[^1] breaches thus risking exposure of personal information.

## Accountability, Responsibility, Liability

Accountability[^2], responsibility[^3] and liability[^4] issues are particularly challenging in the AV context because of the fragmentation of the technology action among many agents (many-hands problem) which hinders traceability.

## Fairness, Non-Discrimination, Justice

Fairness, non-discrimination, and justice relate to reasonableness and impartiality of actions. There are several concerns about biased or discriminatory outcomes in the context of AVs, namely in the selection of passengers in ride-sharing.

## Transparency

[Algorithmic transparency](#user-content-fn-5)[^5] is exceptionally relevant in the AV domain and it can be either prospective (upfront disclosure of the algorithmic processes of a system) or retrospective (description of the system's operation and actions in a particular case). Whereas AI-based algorithms are often developed as a black-box, transparency is an essential tool for securing accountability, predictability, and eventually societal trust in AVs.

## Safety and Cybersecurity

Safety[^6] and computer security[^7] (cybersecurity) are technological risks that pose ethical concerns for AVs. There are unsettled considerations about acceptable safety and cybersecurity levels of AVs, both in mundane and in extreme situations, in order to secure the well-being of users and other traffic agents.

{% hint style="info" %}
### Mundane traffic situations

Entail interactions with traffic agents (pedestrians, cyclists, animals) that require some flexibility. Examples of such situations are crossroads, highway entrances, or crosswalks with limited visibility. These interactions are challenging for AVs because the systems lack intuition and flexibility but also because of the large scale programming that is needed. Coordination over different technical approaches to these traffic situations is crucial to ensure safety.&#x20;
{% endhint %}

{% hint style="info" %}
### Extreme traffic situations

Are unexpected occurrences in the traffic environment which entail danger for the vehicle occupants and other traffic agents (e.g. unexpected appearance of a animal in a highway). Such situations are often depicted in the scientific literature as moral dilemmas, i.e. situations in which the autonomous vehicle (AV) is required to make a difficult moral choice between actions in traffic which will result in different combinations of lives saved and sacrificed.
{% endhint %}

## Common good and Sustainability

AV technology is associated with electrification and ride-sharing which are considered to have a positive environmental impact by reducing energy consumption and carbon emissions. However, because AVs are also expected to improve accessibility, concerns have been raised about the long term effects of this technology on environmental sustainability. &#x20;

## Explainability and Interpretability

Explainable models provide[ interpretable](#user-content-fn-8)[^8] and complete[^9] information about their decision processes.&#x20;

The challenge of explainability is therefore to reach both interpretability and completeness given that accurate explanations are not easily interpretable and the latter often lack predictive power. AVs will make several decisions in traffic  which will need to be explained for legal or financial reasons and there are concerns about the degree to which it is acceptable to simplify the description of the systems in order to increase public trust, yet risking the concealing of undesirable attributes of the system.&#x20;

## Human Oversight, Control, Auditing

Human oversight, control, and auditing of autonomous systems implies the surveillance of the development and running of a technology. Remote human oversight and control of AVs is essential for safety and trust in these systems but it raises ethical problems. There are privacy concerns associated with the human oversight of the AV in mundane activities and it is also not clear which decision should prevail in the context of a takeover i.e. the decision made by AV or the decision made by human controller.&#x20;

Moreover, there are also concerns about the situation awareness of human operators. As more autonomy is added to a system and it becomes more reliable and robust the situation awareness of human operators decreases and they are less likely to take over manual control.

## Dual use problem and military

Weaponized AVs may reduce accidents that soldiers face in combat situations but they also allow greater risks to be taken, thus potentially escalating the length and violence of conflicts.

## Solidarity, Inclusion, Social Cohesion

Automated and shared driving is expected to increase accessibility and create employment opportunities for low-income groups and increase mobility to the senior population, non-drivers, and people with medical conditions and disabilities, thus promoting autonomy and social inclusion. Because the groups who would benefit more from the mobility opportunities provided by AVs are not the ones with higher disposable income, policies should raise the profile of these groups in future AV planning.

## Diversity

A lack of diversity[^10] within the AI community has been reported. Poor diversity in the research and development of AI-based technologies, such as AVs, ultimately entails that a relatively small and homogeneous group of people influence the design of systems.

## Future of Employment

AV technology has been heralded both as a solution for driver shortage and as a social risk resulting from the expected decrease in  public transportation  employment demand. While the social impact of AVs with respect to employment is still unclear, shifts and changes in the transportation workforce are inevitable.

## Public Awareness and Education about AVs and its Risks

Public awareness and education on AV technology is essential both for its development and acceptance. As companies are stakeholders there are concerns about their transparency and influence in the public perception about this technology. Moreover, as an AI-based technology, AVs may undergo the same sort of cyclic pattern of periods of great promise and excitement followed by frustration and lack of research funding. Therefore there are concerns about investment on academic curricula and educational programs revolving around these technologies.&#x20;

## Human Autonomy

In the AV context human autonomy[^11] is associated with the level of influence that humans have in the driving task. Whereas the importance of providing functions that allow drivers to recover control of the vehicle is acknowledged, high levels of automation and remote human oversight of the systems have the potential to undermine the value of human autonomy.&#x20;

## Legislative framework, legal status of AI systems

Autonomous Vehicles, as an AI system, are positioned in multiple legal areas (e.g. Administrative, Civil and Criminal Law) and to benefit from the potential reduction of harm, rules and laws need to be clear. This can only be accomplished if technical professionals and lawmakers strongly cooperate.

## Cultural differences in the ethically aligned design of AI Systems

Cultural values and priorities can differ across developers, regulators, ethicists and all other involved stakeholders with AV systems. These differences are not always aligned with the core values of a research field, if there already is consistency about any core values. For example, profit maximization for stakeholders can potentially undermine the design of AVs for a greater good and this can harm individual cases where ethical decision-making plays a big role.





[^1]: Modern accounts of privacy focus on the control over the inner spheres of personal information from the scrutiny of the public.

[^2]: Accountability entails responsibility but unlike the latter it requires explanations about actions and it cannot be shared.&#x20;

[^3]: Responsibility for an action requires traditionally at least a control condition, i.e. an agent is responsible if it is the agent of the action, and an epistemic condition, i.e. awareness or knowledge of the agent regarding the action.&#x20;

[^4]: Liability is legal or financial responsibility.

[^5]: i.e. openness about the inputs of decisions made by an algorithmic system

[^6]: Safety focuses on the adequate functioning of a system.

[^7]: Security is the ability of a system to resist intentionally malicious actions.

[^8]: description of a system in a way that can be understood by humans

[^9]: accurate description of the operation of a system

[^10]: Diversity is associated with social representation with respect to race, gender, sexual orientation, religion, and socioeconomic status among others.&#x20;

[^11]: Autonomy relates to the capacity for self-governance and decision-making free from coercion.
